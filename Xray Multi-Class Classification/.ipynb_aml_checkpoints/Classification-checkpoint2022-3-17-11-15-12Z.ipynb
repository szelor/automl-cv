{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "\r\n",
        "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You are currently using version 1.38.0 of the Azure ML SDK.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1650193835426
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.workspace import Workspace\r\n",
        "\r\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650193854549
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\r\n",
        "\r\n",
        "cluster_name = \"NC6Cluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    compute_target = ws.compute_targets[cluster_name]\r\n",
        "    print(\"Found existing compute target.\")\r\n",
        "except KeyError:\r\n",
        "    print(\"Creating a new compute target...\")\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(\r\n",
        "        vm_size=\"Standard_NC6\",\r\n",
        "        idle_seconds_before_scaledown=600,\r\n",
        "        min_nodes=0,\r\n",
        "        max_nodes=4,\r\n",
        "    )\r\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "# Can poll for a minimum number of nodes and for a specific timeout.\r\n",
        "# If no min_node_count is provided, it will use the scale settings for the cluster.\r\n",
        "compute_target.wait_for_completion(\r\n",
        "    show_output=True, min_node_count=None, timeout_in_minutes=20\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target.\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650193881930
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment_name = \"automl-image-multiclass-pneunomia\"\r\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650193919663
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "from azureml.data import DataType\r\n",
        "\r\n",
        "# get existing training dataset\r\n",
        "training_dataset_name = \"pneumoniaTrainingDataset\"\r\n",
        "if training_dataset_name in ws.datasets:\r\n",
        "    training_dataset = ws.datasets.get(training_dataset_name)\r\n",
        "    print(\"Found the training dataset\", training_dataset_name)\r\n",
        "\r\n",
        "# get existing validation dataset\r\n",
        "validation_dataset_name = \"pneumoniaValidationDataset\"\r\n",
        "if validation_dataset_name in ws.datasets:\r\n",
        "    validation_dataset = ws.datasets.get(validation_dataset_name)\r\n",
        "    print(\"Found the validation dataset\", validation_dataset_name)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found the training dataset pneumoniaTrainingDataset\nFound the validation dataset pneumoniaValidationDataset\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650194046066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "                                             image_url      label\n0    workspaceblobstore/pneunomiafiles/NORMAL/._IM-...     NORMAL\n1    workspaceblobstore/pneunomiafiles/NORMAL/._IM-...     NORMAL\n2    workspaceblobstore/pneunomiafiles/NORMAL/._IM-...     NORMAL\n3    workspaceblobstore/pneunomiafiles/NORMAL/._IM-...     NORMAL\n4    workspaceblobstore/pneunomiafiles/NORMAL/._IM-...     NORMAL\n..                                                 ...        ...\n591  workspaceblobstore/pneunomiafiles/PNEUMONIA/._...  PNEUMONIA\n592  workspaceblobstore/pneunomiafiles/PNEUMONIA/._...  PNEUMONIA\n593  workspaceblobstore/pneunomiafiles/PNEUMONIA/._...  PNEUMONIA\n594  workspaceblobstore/pneunomiafiles/PNEUMONIA/._...  PNEUMONIA\n595  workspaceblobstore/pneunomiafiles/PNEUMONIA/va...  PNEUMONIA\n\n[596 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_url</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>workspaceblobstore/pneunomiafiles/NORMAL/._IM-...</td>\n      <td>NORMAL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>workspaceblobstore/pneunomiafiles/NORMAL/._IM-...</td>\n      <td>NORMAL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>workspaceblobstore/pneunomiafiles/NORMAL/._IM-...</td>\n      <td>NORMAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>workspaceblobstore/pneunomiafiles/NORMAL/._IM-...</td>\n      <td>NORMAL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>workspaceblobstore/pneunomiafiles/NORMAL/._IM-...</td>\n      <td>NORMAL</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>workspaceblobstore/pneunomiafiles/PNEUMONIA/._...</td>\n      <td>PNEUMONIA</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>workspaceblobstore/pneunomiafiles/PNEUMONIA/._...</td>\n      <td>PNEUMONIA</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>workspaceblobstore/pneunomiafiles/PNEUMONIA/._...</td>\n      <td>PNEUMONIA</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>workspaceblobstore/pneunomiafiles/PNEUMONIA/._...</td>\n      <td>PNEUMONIA</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>workspaceblobstore/pneunomiafiles/PNEUMONIA/va...</td>\n      <td>PNEUMONIA</td>\n    </tr>\n  </tbody>\n</table>\n<p>596 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650194081626
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.automl.core.shared.constants import ImageTask\r\n",
        "from azureml.train.automl import AutoMLImageConfig\r\n",
        "from azureml.train.hyperdrive import GridParameterSampling, choice\r\n",
        "\r\n",
        "image_config_vit = AutoMLImageConfig(\r\n",
        "    task=ImageTask.IMAGE_CLASSIFICATION,\r\n",
        "    compute_target=compute_target,\r\n",
        "    training_data=training_dataset,\r\n",
        "    validation_data=validation_dataset,\r\n",
        "    hyperparameter_sampling=GridParameterSampling({\"model_name\": choice(\"vitb16r224\")}),\r\n",
        "    iterations=1,\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}